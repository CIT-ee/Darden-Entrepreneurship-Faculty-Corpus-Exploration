{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, os.environ['PROJECT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "from gensim import corpora, utils\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from config.resources import path_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:CACHEDIR=/home/banerjee_abhimanyu3/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/banerjee_abhimanyu3/.cache/matplotlib/fontList.json\n",
      "DEBUG:matplotlib.backends:backend module://ipykernel.pylab.backend_inline version unknown\n",
      "DEBUG:matplotlib.backends:backend module://ipykernel.pylab.backend_inline version unknown\n",
      "DEBUG:matplotlib.backends:backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import matplotlib, matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "matplotlib.rcParams.update({\"font.size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTMcorpus(corpora.textcorpus.TextCorpus):\n",
    "\n",
    "    def get_texts(self):\n",
    "        return self.input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbv_df = pd.read_csv(path_to['jbv_meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbv_df.dropna(inplace=True, subset=[ 'AB' ])\n",
    "jbv_df.sort_values('PY', inplace=True)\n",
    "time_slices = jbv_df.PY.value_counts(ascending=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.textcorpus:Initializing dictionary\n",
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(9286 unique tokens: [u'writings', u'workaholism', u'four', u'ornati', u'localized']...) from 910 documents (total 124140 corpus positions)\n",
      "INFO:gensim.models.wrappers.dtmmodel:serializing temporary corpus to /tmp/7d1189_train-mult.dat\n",
      "INFO:gensim.corpora.bleicorpus:no word id mapping provided; initializing from corpus\n",
      "INFO:gensim.corpora.bleicorpus:storing corpus in Blei's LDA-C format into /tmp/7d1189_train-mult.dat\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/tmp/7d1189_train-mult.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'mode': 'wb', 'fileobj': <open file '/tmp/7d1189_train-mult.dat', mode 'wb' at 0x7fde50d61420>, 'encoding': None}\n",
      "INFO:gensim.corpora.bleicorpus:saving vocabulary of 9286 words to /tmp/7d1189_train-mult.dat.vocab\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/tmp/7d1189_train-mult.dat.vocab'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'mode': 'wb', 'fileobj': <open file '/tmp/7d1189_train-mult.dat.vocab', mode 'wb' at 0x7fde50d61390>, 'encoding': None}\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/tmp/7d1189_train-seq.dat'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'mode': 'wb', 'fileobj': <open file '/tmp/7d1189_train-seq.dat', mode 'wb' at 0x7fde50d61420>, 'encoding': None}\n",
      "INFO:gensim.models.wrappers.dtmmodel:training DTM with args --ntopics=22 --model=dtm  --mode=fit --initialize_lda=true --corpus_prefix=/tmp/7d1189_train --outname=/tmp/7d1189_train_out --alpha=0.01 --lda_max_em_iter=10 --lda_sequence_min_iter=6  --lda_sequence_max_iter=20 --top_chain_var=0.005 --rng_seed=0 \n",
      "INFO:gensim.models.wrappers.dtmmodel:Running command ['../data/models/dtm-linux64', '--ntopics=22', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/tmp/7d1189_train', '--outname=/tmp/7d1189_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0']\n",
      "DEBUG:gensim.utils:COMMAND: () {'args': ['../data/models/dtm-linux64', '--ntopics=22', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/tmp/7d1189_train', '--outname=/tmp/7d1189_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0'], 'stderr': -1}\n",
      "INFO:gensim.utils:saving DtmModel object under /home/banerjee_abhimanyu3/darden_faculty_viz/data/interim/topic_models/jbv/dtm_22.pkl, separately None\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'wb', 'uri': '/home/banerjee_abhimanyu3/darden_faculty_viz/data/interim/topic_models/jbv/dtm_22.pkl'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'mode': 'wb', 'fileobj': <open file '/home/banerjee_abhimanyu3/darden_faculty_viz/data/interim/topic_models/jbv/dtm_22.pkl', mode 'wb' at 0x7fde50d61540>, 'encoding': None}\n",
      "INFO:gensim.utils:saved /home/banerjee_abhimanyu3/darden_faculty_viz/data/interim/topic_models/jbv/dtm_22.pkl\n"
     ]
    }
   ],
   "source": [
    "tokenized_abstracts = list(map(lambda a: utils.simple_preprocess(preprocessing.remove_stopwords(a)), jbv_df.AB))\n",
    "dtm_path = os.path.join('..', 'data', 'models', 'dtm-linux64')\n",
    "\n",
    "nb_topics = 22 \n",
    "corpus = DTMcorpus(tokenized_abstracts)\n",
    "path_to_model = path_to['dtm_model'].format('jbv', nb_topics)\n",
    "\n",
    "if os.path.exists(path_to_model) and False:\n",
    "    dtm_model = DtmModel.load(path_to_model)\n",
    "else:\n",
    "    dtm_model = DtmModel(dtm_path, corpus, time_slices, num_topics=nb_topics,\n",
    "                     id2word=corpus.dictionary, initialize_lda=True)\n",
    "    dtm_model.save(path_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic  1 :  0.059*business + 0.016*the + 0.014*family + 0.013*founders + 0.013*managers + 0.011*planning + 0.010*owner + 0.010*management + 0.010*small + 0.010*factors\n",
      "topic  2 :  0.076*entrepreneurs + 0.012*research + 0.011*individuals + 0.011*the + 0.010*study + 0.010*risk + 0.009*performance + 0.009*entrepreneurial + 0.008*satisfaction + 0.008*business\n",
      "topic  3 :  0.063*technology + 0.031*firms + 0.023*external + 0.021*product + 0.020*firm + 0.015*strategies + 0.015*technological + 0.014*acquisition + 0.013*strategy + 0.013*the\n",
      "topic  4 :  0.016*product + 0.014*success + 0.014*market + 0.013*new + 0.012*failure + 0.011*high + 0.010*the + 0.009*initial + 0.009*this + 0.009*related\n",
      "topic  5 :  0.088*venture + 0.053*investors + 0.033*investment + 0.029*capital + 0.020*investments + 0.018*investor + 0.016*ventures + 0.014*capitalists + 0.013*stage + 0.012*market\n",
      "topic  6 :  0.031*involvement + 0.031*family + 0.019*ownership + 0.017*ceos + 0.017*venture + 0.016*public + 0.015*this + 0.015*control + 0.014*conflict + 0.014*founder\n",
      "topic  7 :  0.012*the + 0.012*new + 0.008*this + 0.007*development + 0.007*process + 0.006*growth + 0.006*strategic + 0.006*firms + 0.006*business + 0.006*organizational\n",
      "topic  8 :  0.043*firm + 0.036*firms + 0.022*performance + 0.019*international + 0.015*resources + 0.013*goals + 0.013*corporate + 0.012*the + 0.011*study + 0.011*relationship\n",
      "topic  9 :  0.039*self + 0.025*education + 0.021*the + 0.021*employment + 0.017*employed + 0.015*countries + 0.012*economic + 0.011*this + 0.010*level + 0.009*work\n",
      "topic  10 :  0.035*new + 0.027*entrepreneurial + 0.024*model + 0.020*we + 0.015*entrepreneur + 0.012*inc + 0.011*article + 0.011*elsevier + 0.011*opportunity + 0.010*the\n",
      "topic  11 :  0.041*capital + 0.027*venture + 0.024*value + 0.019*the + 0.014*firms + 0.014*companies + 0.013*equity + 0.011*financial + 0.010*fund + 0.009*managers\n",
      "topic  12 :  0.034*elsevier + 0.033*inc + 0.031*all + 0.029*rights + 0.029*reserved + 0.028*science + 0.027*uncertainty + 0.022*we + 0.012*ipo + 0.011*types\n",
      "topic  13 :  0.051*venture + 0.043*capitalists + 0.036*decision + 0.033*information + 0.019*the + 0.018*informal + 0.018*making + 0.017*criteria + 0.017*vcs + 0.016*decisions\n",
      "topic  14 :  0.015*franchise + 0.014*franchising + 0.013*franchisees + 0.011*the + 0.011*franchisors + 0.009*management + 0.008*values + 0.008*franchisee + 0.008*franchisor + 0.006*cultural\n",
      "topic  15 :  0.050*theory + 0.041*research + 0.025*this + 0.013*inc + 0.013*elsevier + 0.011*field + 0.011*article + 0.011*issue + 0.010*framework + 0.009*we\n",
      "topic  16 :  0.026*activities + 0.019*entrepreneurial + 0.017*alliances + 0.015*environment + 0.014*alliance + 0.014*development + 0.011*china + 0.011*private + 0.009*institutional + 0.009*changes\n",
      "topic  17 :  0.043*venture + 0.020*relationships + 0.018*capital + 0.018*new + 0.017*ventures + 0.017*management + 0.015*network + 0.012*we + 0.011*experience + 0.011*team\n",
      "topic  18 :  0.036*firms + 0.021*women + 0.021*small + 0.019*business + 0.018*growth + 0.015*businesses + 0.014*start + 0.013*size + 0.009*owned + 0.009*men\n",
      "topic  19 :  0.046*venture + 0.031*new + 0.028*university + 0.027*social + 0.020*parent + 0.020*spin + 0.018*financial + 0.018*research + 0.018*off + 0.015*cases\n",
      "topic  20 :  0.026*entrepreneurial + 0.016*elsevier + 0.016*inc + 0.016*relationship + 0.013*rights + 0.012*all + 0.012*reserved + 0.011*opportunities + 0.010*implications + 0.009*theory\n",
      "topic  21 :  0.055*performance + 0.041*new + 0.025*ventures + 0.022*venture + 0.020*industry + 0.016*the + 0.016*research + 0.012*high + 0.012*results + 0.011*sales\n",
      "topic  22 :  0.156*entrepreneurial + 0.043*culture + 0.033*innovation + 0.025*orientation + 0.021*firms + 0.016*study + 0.015*the + 0.014*competitive + 0.013*individualism + 0.012*dimensions\n"
     ]
    }
   ],
   "source": [
    "top_topic_descriptor_ls = dtm_model.show_topics(num_topics=-1, times=1)\n",
    "f = open(path_to['dtm_descriptors'].format('jbv', nb_topics, '1'), 'w')\n",
    "for _idx, topic_descr in enumerate(top_topic_descriptor_ls):\n",
    "    print('topic ', _idx + 1, ': ', topic_descr)\n",
    "    print('topic ', _idx + 1, ': ', topic_descr, file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic descriptors evolution over 27 time slices for topic 3\n",
      "\n",
      "product -> product -> product -> product -> product -> product -> product -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> market -> startups -> startups -> startups \n",
      "\n",
      "success -> success -> success -> success -> success -> success -> market -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> success -> market -> market -> market \n",
      "\n",
      "market -> market -> market -> new -> new -> market -> success -> product -> product -> product -> product -> product -> product -> product -> product -> product -> product -> product -> product -> product -> startups -> startups -> startups -> startups -> success -> success -> success \n",
      "\n",
      "new -> new -> new -> market -> market -> new -> new -> new -> new -> new -> new -> new -> new -> new -> new -> new -> new -> new -> new -> startups -> product -> product -> early -> early -> early -> early -> early \n",
      "\n",
      "failure -> failure -> failure -> failure -> failure -> high -> high -> high -> high -> high -> strategy -> strategy -> the -> the -> the -> the -> the -> the -> startups -> new -> new -> the -> product -> product -> the -> the -> the \n",
      "\n",
      "high -> high -> high -> high -> high -> failure -> failure -> failure -> failure -> strategy -> high -> the -> strategy -> high -> high -> high -> high -> startups -> the -> the -> the -> new -> the -> the -> product -> likely -> likely \n",
      "\n",
      "the -> the -> the -> the -> the -> the -> the -> the -> the -> the -> the -> high -> high -> strategy -> strategy -> strategy -> related -> high -> related -> related -> early -> early -> new -> likely -> likely -> product -> product \n",
      "\n",
      "initial -> initial -> initial -> related -> related -> related -> related -> strategy -> strategy -> failure -> failure -> failure -> initial -> initial -> initial -> related -> likely -> related -> high -> likely -> related -> likely -> likely -> new -> related -> related -> related \n",
      "\n",
      "this -> related -> related -> initial -> initial -> initial -> strategy -> initial -> initial -> initial -> initial -> initial -> failure -> related -> related -> initial -> strategy -> likely -> likely -> high -> likely -> related -> related -> related -> new -> high -> high \n",
      "\n",
      "related -> this -> this -> this -> this -> this -> this -> related -> related -> related -> related -> related -> related -> likely -> likely -> likely -> initial -> initial -> this -> early -> high -> high -> high -> high -> high -> new -> new \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_words, topic_idx = 10, 3\n",
    "topics_over_time = [ [descr for _, descr in dtm_model.show_topic(topicid=topic_idx, time=time_idx, topn=num_words) ] \\\n",
    "                    for time_idx, _ in enumerate(time_slices)]\n",
    "f = open(path_to['dtm_descr_evo'].format('jbv', topic_idx, nb_topics), 'w')\n",
    "print('Topic descriptors evolution over {} time slices for topic {}\\n'.format(len(time_slices), topic_idx))\n",
    "print('Topic descriptors evolution over {} time slices for topic {}\\n'.format(len(time_slices), topic_idx), file=f)\n",
    "for descr_idx in range(num_words):\n",
    "    descr_over_time = [ topics_over_time[time_idx][descr_idx] for time_idx, _ in enumerate(time_slices) ]\n",
    "    print(\" -> \".join(descr_over_time), '\\n')\n",
    "    print(\" -> \".join(descr_over_time), '\\n', file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
